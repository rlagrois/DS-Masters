---
title: "JHerrera_MPayne_RLagrois_week8casestudySec403"
author: "Joshua Herrera, Matthew Payne, Remy Lagrois"
date: "March 6, 2018"
output: html_document
---
```{r include=FALSE}
# Folders named MenTxt and WomenTxt required in your WD 
setwd("~/Unit8CaseStudy")
if(!require(ggplot2)){
  install.packages("ggplot2")
  library(ggplot2)
}
if(!require(RColorBrewer)){
  install.packages("RColorBrewer")
  library(RColorBrewer)
}
if(!require(dplyr)){
  install.packages("dplyr")
  library(dplyr)
}
if(!require(Hmisc)){
  install.packages("Hmisc")
  library(Hmisc)
}
if(!require(car)){
  install.packages("car")
  library(car)
}
library(XML)
```
# Abstract

  As the internet and the amount of data freely stored on it increases, it becomes important to be able to access this vast pool. Web scraping can be used to pull data from free online sources to be used in analysis. In this case study, we scraped text files from a website by using the XML library in R. After scraping, we clean the data and analyze it visually through the use of plots. All of this is performed upon the Cherry Blossom race data from 1999 to 2012, which is freely available online at www.CherryBlossom.org. We discovered that there has been a decline in the median age of runners over time, suggesting that the race is gaining popularity with younger people.

# Introduction

  The objective of this case study is to determine a methodology to scrape data from a website to be used for visualization and analysis. The data we will be working with is free to access from the website and contains multiple variables such as place, running number, name, age, hometown, and time. The variable we will be focusing on is age, however, and we will be performing summary statistics on this variable and viewing how it changes over time.


# Methods

### Web Scraping

```{r, echo = FALSE}
ubase = "http://www.cherryblossom.org/"
url = paste(ubase, "results/1999/cb99m.html", sep = "")


URLSuffixM = 
  c("results/1999/cb99m.html", "results/2000/Cb003m.htm", "results/2001/oof_m.html",
    "results/2002/oofm.htm", "results/2003/CB03-M.HTM",
    "results/2004/men.htm", "results/2005/CB05-M.htm", 
    "results/2006/men.htm", "results/2007/men.htm", 
    "results/2008/men.htm", "results/2009/09cucb-M.htm",
    "results/2010/2010cucb10m-m.htm", 
    "results/2011/2011cucb10m-m.htm",
    "results/2012/2012cucb10m-m.htm")

MenURLs = paste(ubase, URLSuffixM, sep = "")

URLSuffixF = 
  c("results/1999/cb99m.html", "results/2000/Cb003f.htm", "results/2001/oof_f.html",
    "results/2002/ooff.htm", "results/2003/CB03-F.HTM",
    "results/2004/women.htm", "results/2005/CB05-F.htm", 
    "results/2006/women.htm", "results/2007/women.htm", 
    "results/2008/women.htm", "results/2009/09cucb-F.htm",
    "results/2010/2010cucb10m-f.htm", 
    "results/2011/2011cucb10m-f.htm",
    "results/2012/2012cucb10m-f.htm")

FemaleURLs = paste(ubase, URLSuffixF, sep = "")
```

  The first thing to do in this case study is to extract the data from the web. CherryBlossom.org contains the data that will be used in analysis. In order to scrape the website, we first locate the URLs which contain the race data and store them in a list. Then, we define the ExtractResTable function, which will scrape the data from the web-page, downloading it into a .txt file and putting it in a large list. The function uses many else if statements, which are necessary due to the slight format changes between years. The XML package is used to extract the first pre node found on the webpage, where the table is stored for most of the URLs. After extracting the entire table as a string, strsplit is used to seperate lines where ever \r\n is found, which is the code for new line in Windows. For the year 1999, we stringsplit on \n, which is code for end-of-line for Unix systems. In 2000, the XML formatting was poor so our normal method to search for the first pre node would not work. The table of data was stored in the fourth font element, so we told the xmlValue function to scrape it. The last exception we had to make was for the male 2009 page, where each entry to the overall table was its own pre node. The superior node to the pre nodes was stored and the xmlValue extractor function was applied to all pre nodes.

```{r}
extractResTable =
  #
  # Retrieve data from web site, 
  # find the preformatted text,
  # and write lines to return as a character vector.
  #
  function(url = "http://www.cherryblossom.org/results/1999/cb99m.html",
           year = 1999, sex = "male", file = file)
  {
    doc = htmlParse(url, encoding = "utf-8")
    
    if (year == 2000) {
      # Get preformatted text from 4th font element
      # The top file is ill formed so the <pre> search doesn't work.
      ff = getNodeSet(doc, "//font")
      txt = xmlValue(ff[[4]])
      els = strsplit(txt, "\r\n")[[1]]
    }
    else if (year == 2009 & sex == "male") {
      # Get preformatted text from <div class="Section1"> element
      # Each line of results is in a <pre> element
      div1 = getNodeSet(doc, "//div[@class='Section1']")
      pres = getNodeSet(div1[[1]], "//pre")
      els = sapply(pres, xmlValue)
    }
    else if (year == 1999) {
      # Get preformatted text from <pre> elements
      pres = getNodeSet(doc, "//pre")
      txt = xmlValue(pres[[1]])
      els = strsplit(txt, "\n")[[1]] 
    }
    else {
      # Get preformatted text from <pre> elements
      pres = getNodeSet(doc, "//pre")
      txt = xmlValue(pres[[1]])
      els = strsplit(txt, "\r\n")[[1]]   
    } 
    
    if (is.null(file)) return(els)
    # Write the lines as a text file.
    else 
    writeLines(els, con = file)
    return(els)
  }
```

  This extractor function was then run on the male and female URLs using mapply. The function is fed a list of URLs and years, returning a large list containing 14 elements, one for each year. The data is also downloaded to the local working directory /MenTxt or /WomenTxt, which is how we will input the data in our next section. After downloading the data, we double-check the data is correct and well formatted by appling the length function to each year's table. We see that there are no errors in the data, and we are good to proceed.


```{r, echo = FALSE}
years = 1999:2012
```
```{r}
#You must have a MenTxt folder in your working directory!!
menTables = mapply(extractResTable, url = MenURLs, year = years, file=paste(getwd(),"/MenTxt/", years, ".txt", sep = ""))
names(menTables) = years
sapply(menTables, length)

#You must have a WomenTxt folder in your working directory!!
womenTables = mapply(extractResTable, url = FemaleURLs, year = years, sex = rep("female", 14), file=paste(getwd(),"/WomenTxt/", years, ".txt", sep = ""))
names(womenTables) = years
sapply(womenTables, length)
```

### Data Cleaning

Now that we have scraped the race results files from the web into text files, we need to read them into R. We start by looking at the 2011 men's results and immediately notice that there are some issues with the formatting. There is a header in the file that contains extraneous information and a row of equals signs between the header row and the data.

```{r}
els2011 = readLines("MenTxt/2011.txt")
els2011[1:10]
```

We want to identify each of the elements in the file so that we can arrange them in the proper format. We can use regular expressions to identify the spacer row of equals signs and use that row to find the location of the header row and define the data below the spacer row as the body.

```{r}
els = readLines("MenTxt/2012.txt")
eqIndex = grep("^===", els)
spacerRow = els[eqIndex]
headerRow = els[eqIndex - 1]
body = els[ -(1:eqIndex) ]
headerRow
```

We can see that we have located our header row, but the columns that each header represent do not have a character like a comma or tab separating them. We will need a function that can find the location of each header and map the columns based on that pattern. We can then use a function to extract the variables we are interested in for analysis.

```{r findColLocs}
findColLocs = function(spacerRow) {
  spaceLocs = gregexpr(" ", spacerRow)[[1]]
  rowLength = nchar(spacerRow)
  
  if (substring(spacerRow, rowLength, rowLength) != " ")
    return( c(0, spaceLocs, rowLength + 1))
  else return(c(0, spaceLocs))
}
```

```{r}
selectCols = function(shortColNames, headerRow, searchLocs) {
  sapply(shortColNames, function(shortName, headerRow, searchLocs){
    startPos = regexpr(shortName, headerRow)[[1]]
    if (startPos == -1) return( c(NA, NA) )
    index = sum(startPos >= searchLocs)
    c(searchLocs[index] + 1, searchLocs[index + 1])
  }, headerRow = headerRow, searchLocs = searchLocs )
}

```


```{r}
extractVariables = 
  function(file, varNames =c("name", "home", "ag", "gun",
                             "net", "time"))
  {
    
    # Find the index of the row with =s
    eqIndex = grep("^===", file)
    # Extract the two key rows and the data 
    spacerRow = file[eqIndex] 
    headerRow = tolower(file[ eqIndex - 1 ])
    body = file[ -(1 : eqIndex) ]
    # Remove footnotes and blank rows
    footnotes = grep("^[[:blank:]]*(\\*|\\#)", body)
    if ( length(footnotes) > 0 ) body = body[ -footnotes ]
    blanks = grep("^[[:blank:]]*$", body)
    if (length(blanks) > 0 ) body = body[ -blanks ]
    
    
    # Obtain the starting and ending positions of variables   
    searchLocs = findColLocs(spacerRow)
    locCols = selectCols(varNames, headerRow, searchLocs)
    
    Values = mapply(substr, list(body), start = locCols[1, ], 
                    stop = locCols[2, ])
    colnames(Values) = varNames
    
    return(Values)
  }

```

We read the race results for men and women from 1999-2012 into R and then create a matrix using the extractVariables function.

```{r}
wfilenames = paste("WomenTxt/", 1999:2012, ".txt", sep = "")
womenFiles = lapply(wfilenames, readLines)
names(womenFiles) = 1999:2012


mfilenames = paste("MenTxt/", 1999:2012, ".txt", sep = "")
menFiles = lapply(mfilenames, readLines)
names(menFiles) = 1999:2012
```

```{r}
menResMat = lapply(menFiles, extractVariables)
length(menResMat)
```

The male race results matrix is complete, but the women's results for 2001 lack a header. We can add the missing header from the men's 2001 results to fix this problem and then our extract variables function will run without an error.
```{r}
# Fixes file without header
men2001 = readLines("MenTxt/2001.txt")
womenFiles[['2001']][2:3] = men2001[4:5]

womenResMat = lapply(womenFiles, extractVariables)
length(womenResMat)
```


## Age

```{r pressure, echo=FALSE}
#women plot
age = sapply(womenResMat, 
             function(x) as.numeric(x[ , 'ag']))
boxplot(age, ylab = "Age", xlab = "Year")
#count Na values
sapply(age, function(x) sum(is.na(x)))

```

```{r}
#Men plot
age = sapply(menResMat, 
             function(x) as.numeric(x[ , 'ag']))
boxplot(age, ylab = "Age", xlab = "Year")
#count Na values
sapply(age, function(x) sum(is.na(x)))
```

The convert time function creates uniform times from the varying formats the runtimes were recorded in.

```{r}
convertTime = function(time) {
  timePieces = strsplit(time, ":")
  timePieces = sapply(timePieces, as.numeric)
  sapply(timePieces, function(x) {
    if (length(x) == 2) x[1] + x[2]/60
    else 60*x[1] + x[2] + x[3]/60
  })
}
```

The createDF function converts the times for each year, removes placeholder characters and blanks from each column, drops rows where the runner did not complete the race, and outputs a data frame. 

```{r}
createDF = function(Res, year, sex) 
{
  # Determine which time to use
  if ( !is.na(Res[1, 'net']) ) useTime = Res[ , 'net']
  else if ( !is.na(Res[1, 'gun']) ) useTime = Res[ , 'gun']
  else useTime = Res[ , 'time']
  
  # Remove # and * and blanks from time
  useTime = gsub("[#\\*[:blank:]]", "", useTime)
  runTime = convertTime(useTime[ useTime != "" ])
  
  # Drop rows with no time
  Res = Res[ useTime != "", ]
  
  Results = data.frame(year = rep(year, nrow(Res)),
                       sex = rep(sex, nrow(Res)),
                       name = Res[ , 'name'], home = Res[ , 'home'],
                       age = as.numeric(Res[, 'ag']), 
                       runTime = runTime,
                       stringsAsFactors = FALSE)
  invisible(Results)
}
```

When the createDF function is used on the race results, there are thousands of NA values for the year 2006. On closer examination, the columns for that year are shifted and some adjustments are needed so that our previous functions execute for that year. 

```{r}
separatorIdx = grep("^===", menFiles[["2006"]])
separatorRow = menFiles[['2006']][separatorIdx]
separatorRowX = paste(substring(separatorRow, 1, 63), " ", 
                      substring(separatorRow, 65, nchar(separatorRow)), 
                      sep = "")
menFiles[['2006']][separatorIdx] = separatorRowX

menResMat = sapply(menFiles, extractVariables)
menDF = mapply(createDF, menResMat, year = 1999:2012,
               sex = rep("M", 14), SIMPLIFY = FALSE)
```

```{r}
separatorIdx = grep("^===", womenFiles[["2006"]])
separatorRow = womenFiles[['2006']][separatorIdx]
separatorRowX = paste(substring(separatorRow, 1, 63), " ",
                      substring(separatorRow, 65, nchar(separatorRow)),
                      sep = "")
womenFiles[['2006']][separatorIdx] = separatorRowX

womenResMat = sapply(womenFiles, extractVariables)
womenDF = mapply(createDF, womenResMat, year = 1999:2012,
               sex = rep("W", 14), SIMPLIFY = FALSE)

```

```{r}
cbmen = do.call(rbind, menDF)
save(cbmen, file = "cbmen.rda")
dim(cbmen)
summary(cbmen)
```

```{r}
cbWomen = do.call(rbind, womenDF)
save(cbWomen, file = "cbWomen.rda")
dim(cbWomen)
summary(cbWomen)
```

We now have data frames for the men's and women's race results from 1999-2012 to use for our analysis. Although a handful of NA values remain in the age column, they should not be significant to our record set of over 70 thousand runners.

### Data Exploration Analysis
```{r Setup, echo=TRUE, eval=TRUE, include=FALSE}
getwd()
#Load in DFs
load("cbWomen.rda")
summary(cbWomen)
str(cbWomen)

load("cbmen.rda")
summary(cbmen)
str(cbmen)

#Remove remaining NAs for colored boxplot
wData = cbWomen %>% mutate(year = year) %>%
  group_by(year) %>%
  filter(!is.na(age)) %>%
  mutate(med_age = median(age))

mData = cbmen %>% mutate(year = year) %>%
  group_by(year) %>%
  filter(!is.na(age)) %>%
  mutate(med_age = median(age))
```
  
  Before starting analysis the necessary libraries must be loaded in and the dataframes need to be cleaned.  Despite cleaning, some NAs managed to slip by and are filtered out using the code directly below the loading of the dataframes.  While these small number of NAs didn't cause widespread problems, it was found they were an issue for the boxplots colored by median.
  
```{r QQ Plots, echo=TRUE}
#QQ Plots
qqnorm(cbWomen$age, main = "Normal QQ Plot: Women's Age", ylab = "Age")
qqline(cbWomen$age)

qqnorm(cbmen$age, main = "Normal QQ Plot: Men's Age", ylab = "Age")
qqline(cbmen$age)
```

  First, QQ plots were generated for both men and women's ages plotted against a theortical normal distribution.  Both plots show the distribution of age deviates from normal though the women do so more heavily.  The women's distribution appears to be right skewed meaning most runners tended to be young though there were older participants than would be expected under a normal distribution.  The men's QQ plot is closer to a normal age distribution with only a slight right skew.   

```{r Point Boxplot, include=FALSE}
#box plots ages by year
#Women, points with quantile lines
boxY <- scale_y_continuous(name= "Age", breaks = seq(5, 90, 5), limits=c(5,90))
boxX <- scale_x_discrete(name="Year")
wBox <- ggplot(wData, aes(x = factor(year), y = age)) + geom_point(alpha=0.3) +
  stat_summary(fun.data = "median_hilow",  color = "blue", geom="crossbar", mapping = aes(group=year))
wBox <- wBox + boxY + boxX + ggtitle("Boxplot of Ages by Year: Women") + theme(plot.title = element_text(hjust = 0.5))
wBox

#men points with quantile lines
mboxY <- scale_y_continuous(name= "Age", breaks = seq(5, 90, 5), limits=c(5,90))
mboxX <- scale_x_discrete(name="Year")
mBox <- ggplot(mData, aes(x = factor(year), y = age)) + geom_point(alpha=0.3) +
  stat_summary(fun.data = "median_hilow",  color = "darkgreen", geom="crossbar", mapping = aes(group=year))
mBox <- mBox + mboxY + mboxX + ggtitle("Boxplot of Ages by Year: Men") + theme(plot.title = element_text(hjust = 0.5))
mBox
```

```{r Median Colored Plots, echo=TRUE, message=FALSE, warning=FALSE}
#women colored by median
wBox2 <- ggplot(wData, aes(x=factor(year), y=age, fill=med_age)) + geom_boxplot()
wBox2 <- wBox2 + boxY + boxX + ggtitle("Boxplot of Ages by Year: Women") + theme(plot.title = element_text(hjust = 0.5))
wBox2

#men colored by median
mBox2 <- ggplot(mData, aes(x=factor(year), y=age, fill=med_age)) + geom_boxplot(aes(fill=med_age, group=year), 
  color = "black")
mBox2 <- mBox2 + mboxY + mboxX + ggtitle("Boxplot of Ages by Year: Men") + 
  theme(plot.title = element_text(hjust = 0.5)) + scale_fill_gradient(high="darkolivegreen1", low="darkgreen")
mBox2
```

  Next, the boxplots were generated which were colored according to the median age.  This makes it easy to spot the trend present in both the men's and women's participants.  As time goes on, the median age drops.  This trend is slower and more progressive among the men with 2009 finally hitting the floor and seeming to level off.  In the women's data, however, there is a pronounced drop off after 1999 with a more gradual decline until around 2006 when it too begins to level off.
```{r Density Plots 1, echo=TRUE, eval=FALSE, include=FALSE}
#Density Plots
#women point with density lines
wDen2 <- ggplot(cbWomen, aes(x=year, y=age)) + geom_point(size=1) + geom_density_2d(size=1) + 
  ggtitle("Density of Ages by Year: Women") + theme(plot.title = element_text(hjust = 0.5))
wDen2
#men points with density lines
mDen2 <- ggplot(cbmen, aes(x=year, y=age)) + geom_point(size=1) + geom_density_2d(color="darkgreen", size=1) + 
  ggtitle("Density of Ages by Year: Men") + theme(plot.title = element_text(hjust = 0.5))
mDen2
```

```{r Density Plots 2, echo=TRUE, message=FALSE, warning=FALSE}

#women year lines
wDen <- ggplot(cbWomen, aes(x=age)) + geom_density(aes(group=year, color=year)) + 
  ggtitle("Density of Ages by Year: Women") + theme(plot.title = element_text(hjust = 0.5))
wDen

#men year lines
mDen <- ggplot(cbmen, aes(x=age)) + geom_density(aes(group=year, color=year)) + 
  ggtitle("Density of Ages by Year: Men") + theme(plot.title = element_text(hjust = 0.5)) + 
  scale_color_gradient(high="darkolivegreen3", low="gray8")
mDen
```

  To confirm the results we concluded, density plots for men and women were created.  The same trend of age getting lower as time goes on is visible, as well as the underlying skew in the data. The later years have thinner, higher peaks centered lower on the x-axis indicating a larger proportion of the runners in those years were younger. The extreme change between 1999 and 2000 is also clearly visible for the women. 

# Results and Conclusions

  Both sexes have seen a drop in the age of people who participate in the run. In the early years the median age for both men and women was at or near 40. Since then the median age has gotten younger. However, this change has been more extreme for women, both in rapidity and overall change. Between 1999 and 2000 there was a sudden drop in the age of participants. From there it continued to decline up to a difference of nearly 10 years. The men, by comparison, saw a slower and less extreme decline of roughly 5 years from 1999 to 2006. This likely has led to an increase in the competitiveness of the run and could be indicative of an overall changing nature to the race. 

# Future Work

  The focus of future work should be on the results of these changes and perhaps the underlying causes. For example, how has this changed the performance of the runners. Also, how has the population of runners changed; are people traveling from further away to participate, while it tended to be a more local affair in the past? Has the race increased in prestige, causing more young and serious runners to participate? It would also be interesting to see if this trend has continued into current years and examine those questions for the race as it stands today.

# References

Nolan, D, "Data Science in R: A Case Studies Approach to Computational Reasoning and Problem Solving"
